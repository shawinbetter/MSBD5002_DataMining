{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f717e22-8e53-4bf0-a550-4659fc27d347",
   "metadata": {
    "gather": {
     "logged": 1639315566646
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import GRU,LSTM,Input,Conv1D, SpatialDropout1D,Dense, BatchNormalization, Activation, MaxPooling1D, GlobalAveragePooling1D, Add,Flatten,Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d5d6e-c6ce-4d72-b156-bbe4f52a734c",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c72e285-5758-47e9-91cd-3b6e50ad20ce",
   "metadata": {
    "gather": {
     "logged": 1639315323968
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 256) (1600000,) (498, 256) (498,)\n"
     ]
    }
   ],
   "source": [
    "with open('Train_X.npy', 'rb') as f:\n",
    "    Train_X = np.load(f,allow_pickle=True)\n",
    "\n",
    "with open('Train_y.npy', 'rb') as f:\n",
    "    Train_y = np.load(f,allow_pickle=True)\n",
    "\n",
    "with open('Test_X.npy', 'rb') as f:\n",
    "    Test_X = np.load(f,allow_pickle=True)\n",
    "    \n",
    "with open('Test_y.npy', 'rb') as f:\n",
    "    Test_y = np.load(f,allow_pickle=True)\n",
    "\n",
    "print(Train_X.shape,Train_y.shape,Test_X.shape,Test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7072d07a-ded0-4429-86f1-cb163c1cd901",
   "metadata": {
    "gather": {
     "logged": 1639315324025
    }
   },
   "outputs": [],
   "source": [
    "Train_y[Train_y == 4] = 1\n",
    "Test_y[Test_y == 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544e95c4-b08b-4c1e-ad18-4a92cc8bbdbb",
   "metadata": {
    "gather": {
     "logged": 1639322287717
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 4)                 84        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 109\n",
      "Trainable params: 109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1600000 samples, validate on 498 samples\n",
      "Epoch 1/10\n",
      "1600000/1600000 [==============================] - 673s 421us/sample - loss: 0.6927 - accuracy: 0.5139 - val_loss: 0.7395 - val_accuracy: 0.35\n",
      "Epoch 2/10\n",
      "1600000/1600000 [==============================] - 674s 421us/sample - loss: 0.6835 - accuracy: 0.5372 - val_loss: 0.6351 - val_accuracy: 0.39\n",
      "Epoch 3/10\n",
      "1600000/1600000 [==============================] - 674s 421us/sample - loss: 0.6814 - accuracy: 0.5458 - val_loss: 0.7096 - val_accuracy: 0.36\n",
      "Epoch 4/10\n",
      "1600000/1600000 [==============================] - 674s 421us/sample - loss: 0.6802 - accuracy: 0.5465 - val_loss: 0.6566 - val_accuracy: 0.40\n",
      "Epoch 5/10\n",
      "1600000/1600000 [==============================] - 656s 410us/sample - loss: 0.6794 - accuracy: 0.5468 - val_loss: 0.6837 - val_accuracy: 0.37\n",
      "Epoch 6/10\n",
      "1600000/1600000 [==============================] - 656s 410us/sample - loss: 0.6803 - accuracy: 0.5496 - val_loss: 0.6871 - val_accuracy: 0.39\n",
      "Epoch 7/10\n",
      "1600000/1600000 [==============================] - 655s 409us/sample - loss: 0.6816 - accuracy: 0.5426 - val_loss: 0.6912 - val_accuracy: 0.39\n",
      "Epoch 8/10\n",
      "1600000/1600000 [==============================] - 656s 410us/sample - loss: 0.6803 - accuracy: 0.5489 - val_loss: 0.6816 - val_accuracy: 0.40\n",
      "Epoch 9/10\n",
      "1600000/1600000 [==============================] - 669s 418us/sample - loss: 0.6804 - accuracy: 0.5489 - val_loss: 0.7059 - val_accuracy: 0.41\n",
      "Epoch 10/10\n",
      "1600000/1600000 [==============================] - 627s 392us/sample - loss: 0.6793 - accuracy: 0.5525 - val_loss: 0.6587 - val_accuracy: 0.41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4770233668>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=4, input_shape=[256,1]))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def step_decay(epoch):\n",
    "    \"\"\"\n",
    "    a function to decay the learning rate 0.94 every 2 epoch\n",
    "    \"\"\"\n",
    "    initial_lrate = 0.003\n",
    "    drop = 0.95\n",
    "    epochs_drop = 2\n",
    "    end_lr = 0.00001\n",
    "    lrate = initial_lrate * np.power(drop,  \n",
    "        np.floor((1+epoch)/epochs_drop))\n",
    "    if lrate > end_lr:\n",
    "        return lrate\n",
    "    else:\n",
    "        return end_lr\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "el = EarlyStopping(monitor='val_loss', patience=8)\n",
    "\n",
    "#parameter setting\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "optimizer = Adam(0.003)\n",
    "\n",
    "#model compile\n",
    "model = get_model()\n",
    "model.compile(optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(np.expand_dims(Train_X,axis=2),Train_y,epochs = epochs, \n",
    "                                      batch_size = batch_size,validation_data=(np.expand_dims(Test_X,axis=2),Test_y),\n",
    "                                      callbacks=[lr_scheduler,el],verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
