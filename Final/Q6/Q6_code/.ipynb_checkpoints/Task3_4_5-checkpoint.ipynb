{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3707da0-180e-4857-aa85-5e5e6c73a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM,Input,Conv1D, SpatialDropout1D,Dense, BatchNormalization, Activation, MaxPooling1D, GlobalAveragePooling1D, Add,Flatten,Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfe3ed-35ad-4435-94df-8488ed16a7a4",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30e33969-0bee-4b86-812e-2d2f19fbe128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../train.csv\"\n",
    "test_path = \"../test.csv\"\n",
    "augment_path = \"../Q6_output/Q6_generated.csv\"\n",
    "glove_path = '../glove-global-vectors-for-word-representation/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32e024b-d0f5-4a0d-a527-6bc5d471f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path) #load train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922daf77-61a6-4297-8f0a-067cd48aa936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:]).astype(float)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "glove = load_glove_model(glove_path) #glove dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a586ca3-6011-4d5f-960e-775a202dfbe4",
   "metadata": {},
   "source": [
    "#### Create Word index dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55baaf11-afa8-4fd5-a603-0b55f45d7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(glove.keys())\n",
    "word_dic = dict(zip(words,range(len(words))))\n",
    "# reverse the glove\n",
    "glove = dict(zip(range(len(words)),list(glove.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a8002-c6d7-4823-94da-33d50ec45a8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10dd2004-dded-4637-b0a0-e497febec7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,3]\n",
    "y = train.iloc[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99556e8c-14af-43f6-9b45-bc52f4ab286b",
   "metadata": {},
   "source": [
    "#### Clean text and represent using matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6bdb02-35d3-4099-93bb-804c661949b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8j/gcjktp6s2wn3l5pd66pyr67w0000gn/T/ipykernel_83732/1848246562.py:22: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if ans == []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "def map_text(text):\n",
    "    \"\"\"\n",
    "    clean punctuation and map text\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = \"\".join(l for l in text if l not in string.punctuation)\n",
    "    new_text = []\n",
    "    for i in text.split():\n",
    "        try:\n",
    "            new_text.append(word_dic[i])\n",
    "        except:\n",
    "            continue\n",
    "    return new_text\n",
    "\n",
    "def map_index_to_100d(text):\n",
    "    ans = []\n",
    "    for t in text:\n",
    "        if t == -1:\n",
    "            tmp = np.zeros((1,100))\n",
    "        else:\n",
    "            tmp = glove[t].reshape(1,100)\n",
    "        if ans == []:\n",
    "            ans = tmp\n",
    "        else:\n",
    "            ans = np.append(ans,tmp,axis=0)\n",
    "    return ans\n",
    "\n",
    "# map text to vector\n",
    "X = X.apply(map_text)\n",
    "\n",
    "#pad sequence\n",
    "X = pad_sequences(X,padding='post', maxlen=100,value = -1)\n",
    "\n",
    "new_X = []\n",
    "for i in range(X.shape[0]):\n",
    "    new_X.append(map_index_to_100d(X[i]))\n",
    "X = np.array(new_X)\n",
    "print(X.shape)\n",
    "# train['text'] = train['text'].map(map_index_to_100d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684b766-b9db-4c2c-b3dd-bd4b3a77f963",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c9fe6c-dc00-4011-8a94-20c2ee209534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090, 100, 100) (1523, 100, 100) (6090,) (1523,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f086b0-5010-4b98-96c9-77ec750fcc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8j/gcjktp6s2wn3l5pd66pyr67w0000gn/T/ipykernel_83732/1848246562.py:22: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if ans == []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 100, 100)\n",
      "(6936, 100, 100) (6936,)\n"
     ]
    }
   ],
   "source": [
    "### Here we append the augmented text to trainning data and create another pair of training\n",
    "x = pd.read_csv(augment_path)['text']\n",
    "x = x.apply(map_text)\n",
    "x = pad_sequences(x,padding='post', maxlen=100,value = -1)\n",
    "new_x = []\n",
    "for i in range(x.shape[0]):\n",
    "    new_x.append(map_index_to_100d(x[i]))\n",
    "x = np.array(new_x)\n",
    "print(x.shape)\n",
    "\n",
    "X_train_aug = np.append(X_train,x,axis = 0)\n",
    "y_train_aug = np.append(y_train,np.ones((len(x),)),axis = 0)\n",
    "print(X_train_aug.shape, y_train_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f51a33-3df8-4b22-8dc5-c430ad426f51",
   "metadata": {},
   "source": [
    "#### Build Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e1741a0-fadb-44c8-823a-88b5b4e0c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input((100,100)))\n",
    "    model.add(SpatialDropout1D(0.15))\n",
    "\n",
    "    model.add(Conv1D(32,kernel_size=5,activation='relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv1D(32,kernel_size=5,activation='relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv1D(64,kernel_size=5,activation='relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "   \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47e37db5-80d5-426e-8480-cf926008ca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "spatial_dropout1d_10 (Spatia (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 96, 32)            16032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 48, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 44, 32)            5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 22, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 18, 64)            10304     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 9, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 9, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 9, 64)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 34,113\n",
      "Trainable params: 33,857\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def step_decay(epoch):\n",
    "    \"\"\"\n",
    "    a function to decay the learning rate 0.94 every 2 epoch\n",
    "    \"\"\"\n",
    "    initial_lrate = 0.003\n",
    "    drop = 0.95\n",
    "    epochs_drop = 2\n",
    "    end_lr = 0.00001\n",
    "    lrate = initial_lrate * np.power(drop,  \n",
    "        np.floor((1+epoch)/epochs_drop))\n",
    "    if lrate > end_lr:\n",
    "        return lrate\n",
    "    else:\n",
    "        return end_lr\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "el = EarlyStopping(monitor='val_loss', patience=8)\n",
    "\n",
    "#parameter setting\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "optimizer = Adam(0.003)\n",
    "\n",
    "#model compile\n",
    "model = get_model()\n",
    "model.compile(optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ddff81f-9d35-46f0-8e0a-ece1088c223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x35ee1caf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x35ee1caf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x35ee1caf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x29671d040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x29671d040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x29671d040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "48/48 - 1s - loss: 0.5747 - accuracy: 0.7026 - val_loss: 0.5532 - val_accuracy: 0.7630\n",
      "Epoch 2/50\n",
      "48/48 - 1s - loss: 0.4825 - accuracy: 0.7787 - val_loss: 0.5184 - val_accuracy: 0.7663\n",
      "Epoch 3/50\n",
      "48/48 - 1s - loss: 0.4476 - accuracy: 0.8011 - val_loss: 0.5956 - val_accuracy: 0.6980\n",
      "Epoch 4/50\n",
      "48/48 - 1s - loss: 0.4261 - accuracy: 0.8163 - val_loss: 0.4721 - val_accuracy: 0.7840\n",
      "Epoch 5/50\n",
      "48/48 - 1s - loss: 0.4153 - accuracy: 0.8199 - val_loss: 0.4730 - val_accuracy: 0.7833\n",
      "Epoch 6/50\n",
      "48/48 - 1s - loss: 0.3961 - accuracy: 0.8238 - val_loss: 0.4454 - val_accuracy: 0.8050\n",
      "Epoch 7/50\n",
      "48/48 - 1s - loss: 0.3923 - accuracy: 0.8332 - val_loss: 0.4383 - val_accuracy: 0.8004\n",
      "Epoch 8/50\n",
      "48/48 - 1s - loss: 0.3754 - accuracy: 0.8407 - val_loss: 0.4590 - val_accuracy: 0.7853\n",
      "Epoch 9/50\n",
      "48/48 - 1s - loss: 0.3665 - accuracy: 0.8483 - val_loss: 0.4556 - val_accuracy: 0.8011\n",
      "Epoch 10/50\n",
      "48/48 - 1s - loss: 0.3482 - accuracy: 0.8521 - val_loss: 0.5149 - val_accuracy: 0.8083\n",
      "Epoch 11/50\n",
      "48/48 - 1s - loss: 0.3383 - accuracy: 0.8581 - val_loss: 0.5069 - val_accuracy: 0.8043\n",
      "Epoch 12/50\n",
      "48/48 - 1s - loss: 0.3265 - accuracy: 0.8622 - val_loss: 0.4690 - val_accuracy: 0.8056\n",
      "Epoch 13/50\n",
      "48/48 - 1s - loss: 0.3078 - accuracy: 0.8747 - val_loss: 0.4841 - val_accuracy: 0.7951\n",
      "Epoch 14/50\n",
      "48/48 - 1s - loss: 0.3119 - accuracy: 0.8685 - val_loss: 0.4588 - val_accuracy: 0.8096\n",
      "Epoch 15/50\n",
      "48/48 - 1s - loss: 0.3029 - accuracy: 0.8739 - val_loss: 0.4759 - val_accuracy: 0.7997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x388e31190>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = epochs, batch_size = batch_size,validation_data=(X_test,y_test),callbacks=[lr_scheduler,el],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffd8a7aa-86d0-43f4-a101-e4204a0b3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x35ed34a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x35ed34a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x35ed34a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       874\n",
      "           1       0.84      0.65      0.73       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.78      0.79      1523\n",
      "weighted avg       0.81      0.80      0.79      1523\n",
      "\n",
      "Test set AUC score: 0.7804931367744073\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Test set AUC score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f927c4-c465-442a-94c9-03a5f0595ea8",
   "metadata": {},
   "source": [
    "### Use Augmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87065041-3928-4213-afb1-a750414d0e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x3890ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x3890ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x3890ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x388f30700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x388f30700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x388f30700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "55/55 - 1s - loss: 0.5316 - accuracy: 0.7351 - val_loss: 0.4640 - val_accuracy: 0.8109\n",
      "Epoch 2/50\n",
      "55/55 - 1s - loss: 0.4555 - accuracy: 0.7917 - val_loss: 0.4697 - val_accuracy: 0.7951\n",
      "Epoch 3/50\n",
      "55/55 - 1s - loss: 0.4266 - accuracy: 0.8123 - val_loss: 0.4555 - val_accuracy: 0.7879\n",
      "Epoch 4/50\n",
      "55/55 - 1s - loss: 0.4081 - accuracy: 0.8222 - val_loss: 0.4208 - val_accuracy: 0.8181\n",
      "Epoch 5/50\n",
      "55/55 - 1s - loss: 0.3875 - accuracy: 0.8322 - val_loss: 0.4291 - val_accuracy: 0.8168\n",
      "Epoch 6/50\n",
      "55/55 - 1s - loss: 0.3697 - accuracy: 0.8411 - val_loss: 0.4317 - val_accuracy: 0.8155\n",
      "Epoch 7/50\n",
      "55/55 - 1s - loss: 0.3553 - accuracy: 0.8467 - val_loss: 0.4367 - val_accuracy: 0.8102\n",
      "Epoch 8/50\n",
      "55/55 - 1s - loss: 0.3478 - accuracy: 0.8534 - val_loss: 0.4506 - val_accuracy: 0.8070\n",
      "Epoch 9/50\n",
      "55/55 - 1s - loss: 0.3256 - accuracy: 0.8651 - val_loss: 0.4422 - val_accuracy: 0.8109\n",
      "Epoch 10/50\n",
      "55/55 - 1s - loss: 0.3140 - accuracy: 0.8671 - val_loss: 0.4677 - val_accuracy: 0.7997\n",
      "Epoch 11/50\n",
      "55/55 - 1s - loss: 0.3096 - accuracy: 0.8698 - val_loss: 0.4774 - val_accuracy: 0.8030\n",
      "Epoch 12/50\n",
      "55/55 - 1s - loss: 0.3038 - accuracy: 0.8738 - val_loss: 0.4662 - val_accuracy: 0.8096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x388eeb460>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aug = get_model()\n",
    "model_aug.compile(optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_aug.fit(X_train_aug,y_train_aug,epochs = epochs, batch_size = batch_size,validation_data=(X_test,y_test),callbacks=[lr_scheduler,el],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "489ab120-66c1-4829-a5ec-c143e1db67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x394a8c790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x394a8c790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x394a8c790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       874\n",
      "           1       0.84      0.68      0.75       649\n",
      "\n",
      "    accuracy                           0.81      1523\n",
      "   macro avg       0.82      0.79      0.80      1523\n",
      "weighted avg       0.81      0.81      0.81      1523\n",
      "\n",
      "Test set AUC score: 0.7926443780785789\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_aug.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Test set AUC score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1a64d-fba0-4334-927c-bd9d03f05d26",
   "metadata": {},
   "source": [
    "#### Use Full data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20fdd5bb-7126-4976-b18b-d5ba445d4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x398db9ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x398db9ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x398db9ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x3989bfaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x3989bfaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x3989bfaf0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x39ba5e070>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### No Augmentated\n",
    "model = get_model()\n",
    "model.compile(optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X,y,epochs = epochs, batch_size = batch_size,validation_data=(X_test,y_test),callbacks=[lr_scheduler,el],verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62e2c13a-2426-4e90-b20a-9105a4f5ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x35daba670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x35daba670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x35daba670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x38a2c1af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x38a2c1af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x38a2c1af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x39894c520>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aug = np.append(X,x,axis = 0)\n",
    "y_aug = np.append(y,np.ones((len(x),)),axis = 0)\n",
    "\n",
    "#### Augmentated\n",
    "model_aug = get_model()\n",
    "model_aug.compile(optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_aug.fit(X_aug,y_aug,epochs = epochs, batch_size = batch_size,validation_data=(X_test,y_test),callbacks=[lr_scheduler,el],verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b457e1b-1b81-4394-bc0b-c940ee8a6f27",
   "metadata": {},
   "source": [
    "#### Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c32636ef-922e-469a-86a4-dd5aeffdf4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8j/gcjktp6s2wn3l5pd66pyr67w0000gn/T/ipykernel_83732/1848246562.py:22: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if ans == []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3263, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "## Prepare Test data\n",
    "test = pd.read_csv(test_path) #load train\n",
    "X_test = test.iloc[:,3]\n",
    "\n",
    "# map text to vector\n",
    "X_test = X_test.apply(map_text)\n",
    "\n",
    "#pad sequence\n",
    "X_test = pad_sequences(X_test,padding='post', maxlen=100,value = -1)\n",
    "\n",
    "new_X = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    new_X.append(map_index_to_100d(X_test[i]))\n",
    "X_test = np.array(new_X)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d8c3047-fa81-441c-865b-67e39cd29f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x3a35b9b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x3a35b9b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x3a35b9b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "pred = (model.predict(X_test) >= threshold).astype(int)\n",
    "pred_aug = (model_aug.predict(X_test) >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc113e6a-5cf4-46d6-af1a-c13e74a0ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':test['id'],'target':pred.reshape(1,len(pred))[0]}).to_csv('../Q6_output/Q6_results_plain.csv',index=None)\n",
    "pd.DataFrame({'id':test['id'],'target':pred_aug.reshape(1,len(pred_aug))[0]}).to_csv('../Q6_output/Q6_results_augmented.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202984b-64b8-4605-ac51-bc1964f3e440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
