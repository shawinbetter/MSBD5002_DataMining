{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2c0272-2ebb-462b-aae5-52f908c78b22",
   "metadata": {
    "gather": {
     "logged": 1639208708935
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189117b-c250-42f6-8a15-66bb6db9efb7",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4d4aa2-ba6d-494b-863b-773815e87412",
   "metadata": {
    "gather": {
     "logged": 1639208708995
    }
   },
   "outputs": [],
   "source": [
    "confirmed_path = \"../covid19_confirmed_global.txt\"\n",
    "death_path = \"../covid19_deaths_global.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d30725-b486-4759-8aaf-4d32839bbb12",
   "metadata": {
    "gather": {
     "logged": 1639208709971
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 678) (1, 678)\n"
     ]
    }
   ],
   "source": [
    "confirmed = pd.read_csv(confirmed_path)\n",
    "death = pd.read_csv(death_path)\n",
    "## Select US data\n",
    "confirmed = confirmed[confirmed['Country/Region'] == 'US']\n",
    "death = death[death['Country/Region'] == 'US']\n",
    "\n",
    "## Just Keep Time Series Data\n",
    "confirmed_train = np.array(confirmed.iloc[:,4::])\n",
    "death_train = np.array(death.iloc[:,4::])\n",
    "\n",
    "print(confirmed_train.shape,death_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e720b9-d15a-4da7-ae39-b8613426aac1",
   "metadata": {},
   "source": [
    "#### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df62330f-a242-4f9d-b0f9-4ba7dd38dfb6",
   "metadata": {
    "gather": {
     "logged": 1639208710032
    }
   },
   "outputs": [],
   "source": [
    "#record mean & std\n",
    "confirmed_mean,confirmed_std = confirmed_train.mean(),confirmed_train.std()\n",
    "death_mean,death_std = death_train.mean(),death_train.std()\n",
    "\n",
    "#normalize\n",
    "confirmed_train = (confirmed_train - confirmed_mean) / confirmed_std \n",
    "death_train = (death_train - death_mean) / death_std "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76532f-98a7-4ec2-b334-6f68ca60be12",
   "metadata": {},
   "source": [
    "### create seq-to-seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02872fc8-326b-43b2-ab94-9b8bef7b7aa5",
   "metadata": {
    "gather": {
     "logged": 1639208710177
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 21, 1) (650, 7, 1)\n",
      "(650, 21, 1) (650, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(X, time_steps=7):\n",
    "    Xs, ys = [],[]\n",
    "    for i in range(len(X) - time_steps*4):\n",
    "        Xs.append(X[i:(i + time_steps*3)])\n",
    "        ys.append(X[(i + time_steps*3):(i + time_steps*4)])\n",
    "    return np.expand_dims(np.array(Xs),axis=2),np.expand_dims(np.array(ys),axis=2)\n",
    "\n",
    "TIME_STEPS = 7 #a week\n",
    "\n",
    "#c stands for confimed\n",
    "X_c, y_c = create_dataset(\n",
    "  confirmed_train[0],\n",
    "  TIME_STEPS\n",
    ")\n",
    "\n",
    "#d stands for death\n",
    "X_d, y_d = create_dataset(\n",
    "  death_train[0],\n",
    "  TIME_STEPS\n",
    ")\n",
    "\n",
    "print(X_c.shape,y_c.shape)\n",
    "print(X_d.shape,y_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b377b8a-18a8-49c3-9ff9-a2c780d444c8",
   "metadata": {},
   "source": [
    "#### Use LSTM to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f185c17c-144e-408a-acce-a1ec1b407282",
   "metadata": {
    "gather": {
     "logged": 1639208710277
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.LSTM(units=256, input_shape=[21,1]))\n",
    "    model.add(keras.layers.Dense(64))\n",
    "    model.add(keras.layers.Dense(32))\n",
    "    model.add(keras.layers.Dense(7))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725f889-1ad3-4d91-93bb-2153bb381dec",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f21a320-d4bf-46bc-b77c-ddc33b9430a4",
   "metadata": {
    "gather": {
     "logged": 1639208771200
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 650 samples\n",
      "Epoch 1/100\n",
      "650/650 [==============================] - 2s 3ms/sample - loss: 0.767\n",
      "Epoch 2/100\n",
      "650/650 [==============================] - 1s 881us/sample - loss: 0.320\n",
      "Epoch 3/100\n",
      "650/650 [==============================] - 1s 916us/sample - loss: 0.078\n",
      "Epoch 4/100\n",
      "650/650 [==============================] - 1s 942us/sample - loss: 0.019\n",
      "Epoch 5/100\n",
      "650/650 [==============================] - 1s 881us/sample - loss: 0.014\n",
      "Epoch 6/100\n",
      "650/650 [==============================] - 1s 931us/sample - loss: 0.014\n",
      "Epoch 7/100\n",
      "650/650 [==============================] - 1s 924us/sample - loss: 0.008\n",
      "Epoch 8/100\n",
      "650/650 [==============================] - 1s 913us/sample - loss: 0.010\n",
      "Epoch 9/100\n",
      "650/650 [==============================] - 1s 926us/sample - loss: 0.011\n",
      "Epoch 10/100\n",
      "650/650 [==============================] - 1s 967us/sample - loss: 0.007\n",
      "Epoch 11/100\n",
      "650/650 [==============================] - 1s 958us/sample - loss: 0.009\n",
      "Epoch 12/100\n",
      "650/650 [==============================] - 1s 989us/sample - loss: 0.010\n",
      "Epoch 13/100\n",
      "650/650 [==============================] - 1s 975us/sample - loss: 0.006\n",
      "Epoch 14/100\n",
      "650/650 [==============================] - 1s 878us/sample - loss: 0.007\n",
      "Epoch 15/100\n",
      "650/650 [==============================] - 1s 908us/sample - loss: 0.009\n",
      "Epoch 16/100\n",
      "650/650 [==============================] - 1s 921us/sample - loss: 0.005\n",
      "Epoch 17/100\n",
      "650/650 [==============================] - 1s 909us/sample - loss: 0.006\n",
      "Epoch 18/100\n",
      "650/650 [==============================] - 1s 868us/sample - loss: 0.008\n",
      "Epoch 19/100\n",
      "650/650 [==============================] - 1s 869us/sample - loss: 0.004\n",
      "Epoch 20/100\n",
      "650/650 [==============================] - 1s 888us/sample - loss: 0.005\n",
      "Epoch 21/100\n",
      "650/650 [==============================] - 1s 898us/sample - loss: 0.008\n",
      "Epoch 22/100\n",
      "650/650 [==============================] - 1s 920us/sample - loss: 0.004\n",
      "Epoch 23/100\n",
      "650/650 [==============================] - 1s 897us/sample - loss: 0.003\n",
      "Epoch 24/100\n",
      "650/650 [==============================] - 1s 911us/sample - loss: 0.007\n",
      "Epoch 25/100\n",
      "650/650 [==============================] - 1s 888us/sample - loss: 0.003\n",
      "Epoch 26/100\n",
      "650/650 [==============================] - 1s 908us/sample - loss: 0.002\n",
      "Epoch 27/100\n",
      "650/650 [==============================] - 1s 866us/sample - loss: 0.007\n",
      "Epoch 28/100\n",
      "650/650 [==============================] - 1s 903us/sample - loss: 0.003\n",
      "Epoch 29/100\n",
      "650/650 [==============================] - 1s 917us/sample - loss: 0.002\n",
      "Epoch 30/100\n",
      "650/650 [==============================] - 1s 880us/sample - loss: 0.006\n",
      "Epoch 31/100\n",
      "650/650 [==============================] - 1s 923us/sample - loss: 0.002\n",
      "Epoch 32/100\n",
      "650/650 [==============================] - 1s 930us/sample - loss: 0.001\n",
      "Epoch 33/100\n",
      "650/650 [==============================] - 1s 916us/sample - loss: 0.005\n",
      "Epoch 34/100\n",
      "650/650 [==============================] - 1s 899us/sample - loss: 0.001\n",
      "Epoch 35/100\n",
      "650/650 [==============================] - 1s 927us/sample - loss: 0.001\n",
      "Epoch 36/100\n",
      "650/650 [==============================] - 1s 936us/sample - loss: 0.004\n",
      "Epoch 37/100\n",
      "650/650 [==============================] - 1s 915us/sample - loss: 0.001\n",
      "Epoch 38/100\n",
      "650/650 [==============================] - 1s 934us/sample - loss: 0.001\n",
      "Epoch 39/100\n",
      "650/650 [==============================] - 1s 960us/sample - loss: 0.002\n",
      "Epoch 40/100\n",
      "650/650 [==============================] - 1s 931us/sample - loss: 0.001\n",
      "Epoch 41/100\n",
      "650/650 [==============================] - 1s 933us/sample - loss: 0.001\n",
      "Epoch 42/100\n",
      "650/650 [==============================] - 1s 947us/sample - loss: 0.001\n",
      "Epoch 43/100\n",
      "650/650 [==============================] - 1s 966us/sample - loss: 0.001\n",
      "Epoch 44/100\n",
      "650/650 [==============================] - 1s 940us/sample - loss: 0.001\n",
      "Epoch 45/100\n",
      "650/650 [==============================] - 1s 913us/sample - loss: 0.001\n",
      "Epoch 46/100\n",
      "650/650 [==============================] - 1s 918us/sample - loss: 0.001\n",
      "Epoch 47/100\n",
      "650/650 [==============================] - 1s 879us/sample - loss: 0.001\n",
      "Epoch 48/100\n",
      "650/650 [==============================] - 1s 897us/sample - loss: 0.001\n",
      "Epoch 49/100\n",
      "650/650 [==============================] - 1s 889us/sample - loss: 0.001\n",
      "Epoch 50/100\n",
      "650/650 [==============================] - 1s 920us/sample - loss: 0.001\n",
      "Epoch 51/100\n",
      "650/650 [==============================] - 1s 901us/sample - loss: 0.001\n",
      "Epoch 52/100\n",
      "650/650 [==============================] - 1s 896us/sample - loss: 0.001\n",
      "Epoch 53/100\n",
      "650/650 [==============================] - 1s 924us/sample - loss: 0.001\n",
      "Epoch 54/100\n",
      "650/650 [==============================] - 1s 951us/sample - loss: 0.002\n",
      "Epoch 55/100\n",
      "650/650 [==============================] - 1s 890us/sample - loss: 0.002\n",
      "Epoch 56/100\n",
      "650/650 [==============================] - 1s 909us/sample - loss: 0.002\n",
      "Epoch 57/100\n",
      "650/650 [==============================] - 1s 925us/sample - loss: 0.003\n",
      "Epoch 58/100\n",
      "650/650 [==============================] - 1s 887us/sample - loss: 0.002\n",
      "Epoch 59/100\n",
      "650/650 [==============================] - 1s 874us/sample - loss: 0.002\n",
      "Epoch 60/100\n",
      "650/650 [==============================] - 1s 880us/sample - loss: 0.003\n",
      "Epoch 61/100\n",
      "650/650 [==============================] - 1s 914us/sample - loss: 0.003\n",
      "Epoch 62/100\n",
      "650/650 [==============================] - 1s 901us/sample - loss: 0.003\n",
      "Epoch 63/100\n",
      "650/650 [==============================] - 1s 899us/sample - loss: 0.003\n",
      "Epoch 64/100\n",
      "650/650 [==============================] - 1s 921us/sample - loss: 0.003\n",
      "Epoch 65/100\n",
      "650/650 [==============================] - 1s 897us/sample - loss: 0.002\n",
      "Epoch 66/100\n",
      "650/650 [==============================] - 1s 890us/sample - loss: 0.003\n",
      "Epoch 67/100\n",
      "650/650 [==============================] - 1s 886us/sample - loss: 0.002\n",
      "Epoch 68/100\n",
      "650/650 [==============================] - 1s 898us/sample - loss: 0.003\n",
      "Epoch 69/100\n",
      "650/650 [==============================] - 1s 905us/sample - loss: 0.002\n",
      "Epoch 70/100\n",
      "650/650 [==============================] - 1s 897us/sample - loss: 0.004\n",
      "Epoch 71/100\n",
      "650/650 [==============================] - 1s 914us/sample - loss: 0.002\n",
      "Epoch 72/100\n",
      "650/650 [==============================] - 1s 868us/sample - loss: 0.003\n",
      "Epoch 73/100\n",
      "650/650 [==============================] - 1s 917us/sample - loss: 0.001\n",
      "Epoch 74/100\n",
      "650/650 [==============================] - 1s 869us/sample - loss: 0.002\n",
      "Epoch 75/100\n",
      "650/650 [==============================] - 1s 889us/sample - loss: 9.4073e-0\n",
      "Epoch 76/100\n",
      "650/650 [==============================] - 1s 872us/sample - loss: 0.001\n",
      "Epoch 77/100\n",
      "650/650 [==============================] - 1s 906us/sample - loss: 9.0670e-0\n",
      "Epoch 78/100\n",
      "650/650 [==============================] - 1s 875us/sample - loss: 0.001\n",
      "Epoch 79/100\n",
      "650/650 [==============================] - 1s 908us/sample - loss: 8.9892e-0\n",
      "Epoch 80/100\n",
      "650/650 [==============================] - 1s 902us/sample - loss: 0.001\n",
      "Epoch 81/100\n",
      "650/650 [==============================] - 1s 869us/sample - loss: 9.0590e-0\n",
      "Epoch 82/100\n",
      "650/650 [==============================] - 1s 887us/sample - loss: 0.001\n",
      "Epoch 83/100\n",
      "650/650 [==============================] - 1s 943us/sample - loss: 9.6582e-0\n",
      "Epoch 84/100\n",
      "650/650 [==============================] - 1s 889us/sample - loss: 0.001\n",
      "Epoch 85/100\n",
      "650/650 [==============================] - 1s 905us/sample - loss: 0.001\n",
      "Epoch 86/100\n",
      "650/650 [==============================] - 1s 907us/sample - loss: 0.001\n",
      "Epoch 87/100\n",
      "650/650 [==============================] - 1s 896us/sample - loss: 0.001\n",
      "Epoch 88/100\n",
      "650/650 [==============================] - 1s 895us/sample - loss: 0.001\n",
      "Epoch 89/100\n",
      "650/650 [==============================] - 1s 889us/sample - loss: 0.001\n",
      "Epoch 90/100\n",
      "650/650 [==============================] - 1s 887us/sample - loss: 0.001\n",
      "Epoch 91/100\n",
      "650/650 [==============================] - 1s 876us/sample - loss: 0.001\n",
      "Epoch 92/100\n",
      "650/650 [==============================] - 1s 932us/sample - loss: 0.001\n",
      "Epoch 93/100\n",
      "650/650 [==============================] - 1s 864us/sample - loss: 0.002\n",
      "Epoch 94/100\n",
      "650/650 [==============================] - 1s 867us/sample - loss: 0.002\n",
      "Epoch 95/100\n",
      "650/650 [==============================] - 1s 863us/sample - loss: 0.002\n",
      "Epoch 96/100\n",
      "650/650 [==============================] - 1s 869us/sample - loss: 0.002\n",
      "Epoch 97/100\n",
      "650/650 [==============================] - 1s 901us/sample - loss: 0.001\n",
      "Epoch 98/100\n",
      "650/650 [==============================] - 1s 877us/sample - loss: 0.002\n",
      "Epoch 99/100\n",
      "650/650 [==============================] - 1s 884us/sample - loss: 0.001\n",
      "Epoch 100/100\n",
      "650/650 [==============================] - 1s 870us/sample - loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_c, y_c,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509f44cf-fd05-48b9-a695-1644ce68c0b8",
   "metadata": {
    "gather": {
     "logged": 1639208771618
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of confirmed in last 7 days: [[48503320. 48549190. 48496430. 48679452. 48802000. 48891584. 48916490.]]\n",
      "The daily new confirmed is: [ 65365.  45872. -52760. 183020. 122548.  89584.  24904.]\n"
     ]
    }
   ],
   "source": [
    "last_21 = confirmed_train[0][-21::].reshape(1,21,1)\n",
    "pred = model.predict(last_21)\n",
    "pred = (pred * confirmed_std) + confirmed_mean\n",
    "print(\"prediction of confirmed in last 7 days:\",pred)\n",
    "\n",
    "tmp = [(confirmed_train[0][-1] * confirmed_std) + confirmed_mean]\n",
    "tmp.extend(list(pred[0]))\n",
    "print(\"The daily new confirmed is:\",np.diff(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354c781-77a7-4ea5-bdca-bf8ce21f8bd6",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0f4710-7c9b-4e0f-973f-0205b9dcb543",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1639208834917
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 650 samples\n",
      "Epoch 1/100\n",
      "650/650 [==============================] - 2s 4ms/sample - loss: 0.849\n",
      "Epoch 2/100\n",
      "650/650 [==============================] - 1s 941us/sample - loss: 0.514\n",
      "Epoch 3/100\n",
      "650/650 [==============================] - 1s 974us/sample - loss: 0.092\n",
      "Epoch 4/100\n",
      "650/650 [==============================] - 1s 927us/sample - loss: 0.028\n",
      "Epoch 5/100\n",
      "650/650 [==============================] - 1s 990us/sample - loss: 0.043\n",
      "Epoch 6/100\n",
      "650/650 [==============================] - 1s 887us/sample - loss: 0.017\n",
      "Epoch 7/100\n",
      "650/650 [==============================] - 1s 901us/sample - loss: 0.015\n",
      "Epoch 8/100\n",
      "650/650 [==============================] - 1s 900us/sample - loss: 0.015\n",
      "Epoch 9/100\n",
      "650/650 [==============================] - 1s 906us/sample - loss: 0.010\n",
      "Epoch 10/100\n",
      "650/650 [==============================] - 1s 902us/sample - loss: 0.010\n",
      "Epoch 11/100\n",
      "650/650 [==============================] - 1s 923us/sample - loss: 0.010\n",
      "Epoch 12/100\n",
      "650/650 [==============================] - 1s 887us/sample - loss: 0.009\n",
      "Epoch 13/100\n",
      "650/650 [==============================] - 1s 912us/sample - loss: 0.008\n",
      "Epoch 14/100\n",
      "650/650 [==============================] - 1s 912us/sample - loss: 0.008\n",
      "Epoch 15/100\n",
      "650/650 [==============================] - 1s 954us/sample - loss: 0.008\n",
      "Epoch 16/100\n",
      "650/650 [==============================] - 1s 918us/sample - loss: 0.007\n",
      "Epoch 17/100\n",
      "650/650 [==============================] - 1s 893us/sample - loss: 0.006\n",
      "Epoch 18/100\n",
      "650/650 [==============================] - 1s 909us/sample - loss: 0.007\n",
      "Epoch 19/100\n",
      "650/650 [==============================] - 1s 905us/sample - loss: 0.006\n",
      "Epoch 20/100\n",
      "650/650 [==============================] - 1s 925us/sample - loss: 0.005\n",
      "Epoch 21/100\n",
      "650/650 [==============================] - 1s 886us/sample - loss: 0.005\n",
      "Epoch 22/100\n",
      "650/650 [==============================] - 1s 929us/sample - loss: 0.005\n",
      "Epoch 23/100\n",
      "650/650 [==============================] - 1s 929us/sample - loss: 0.004\n",
      "Epoch 24/100\n",
      "650/650 [==============================] - 1s 918us/sample - loss: 0.004\n",
      "Epoch 25/100\n",
      "650/650 [==============================] - 1s 870us/sample - loss: 0.005\n",
      "Epoch 26/100\n",
      "650/650 [==============================] - 1s 914us/sample - loss: 0.004\n",
      "Epoch 27/100\n",
      "650/650 [==============================] - 1s 947us/sample - loss: 0.004\n",
      "Epoch 28/100\n",
      "650/650 [==============================] - 1s 919us/sample - loss: 0.004\n",
      "Epoch 29/100\n",
      "650/650 [==============================] - 1s 968us/sample - loss: 0.004\n",
      "Epoch 30/100\n",
      "650/650 [==============================] - 1s 908us/sample - loss: 0.003\n",
      "Epoch 31/100\n",
      "650/650 [==============================] - 1s 927us/sample - loss: 0.003\n",
      "Epoch 32/100\n",
      "650/650 [==============================] - 1s 927us/sample - loss: 0.003\n",
      "Epoch 33/100\n",
      "650/650 [==============================] - 1s 943us/sample - loss: 0.003\n",
      "Epoch 34/100\n",
      "650/650 [==============================] - 1s 914us/sample - loss: 0.003\n",
      "Epoch 35/100\n",
      "650/650 [==============================] - 1s 966us/sample - loss: 0.002\n",
      "Epoch 36/100\n",
      "650/650 [==============================] - 1s 1ms/sample - loss: 0.003\n",
      "Epoch 37/100\n",
      "650/650 [==============================] - 1s 980us/sample - loss: 0.002\n",
      "Epoch 38/100\n",
      "650/650 [==============================] - 1s 997us/sample - loss: 0.002\n",
      "Epoch 39/100\n",
      "650/650 [==============================] - 1s 932us/sample - loss: 0.003\n",
      "Epoch 40/100\n",
      "650/650 [==============================] - 1s 1ms/sample - loss: 0.002\n",
      "Epoch 41/100\n",
      "650/650 [==============================] - 1s 993us/sample - loss: 0.002\n",
      "Epoch 42/100\n",
      "650/650 [==============================] - 1s 970us/sample - loss: 0.002\n",
      "Epoch 43/100\n",
      "650/650 [==============================] - 1s 944us/sample - loss: 0.002\n",
      "Epoch 44/100\n",
      "650/650 [==============================] - 1s 956us/sample - loss: 0.003\n",
      "Epoch 45/100\n",
      "650/650 [==============================] - 1s 950us/sample - loss: 0.002\n",
      "Epoch 46/100\n",
      "650/650 [==============================] - 1s 978us/sample - loss: 0.003\n",
      "Epoch 47/100\n",
      "650/650 [==============================] - 1s 1ms/sample - loss: 0.003\n",
      "Epoch 48/100\n",
      "650/650 [==============================] - 1s 918us/sample - loss: 0.002\n",
      "Epoch 49/100\n",
      "650/650 [==============================] - 1s 962us/sample - loss: 0.004\n",
      "Epoch 50/100\n",
      "650/650 [==============================] - 1s 932us/sample - loss: 0.003\n",
      "Epoch 51/100\n",
      "650/650 [==============================] - 1s 955us/sample - loss: 0.003\n",
      "Epoch 52/100\n",
      "650/650 [==============================] - 1s 991us/sample - loss: 0.004\n",
      "Epoch 53/100\n",
      "650/650 [==============================] - 1s 922us/sample - loss: 0.003\n",
      "Epoch 54/100\n",
      "650/650 [==============================] - 1s 944us/sample - loss: 0.003\n",
      "Epoch 55/100\n",
      "650/650 [==============================] - 1s 945us/sample - loss: 0.003\n",
      "Epoch 56/100\n",
      "650/650 [==============================] - 1s 1ms/sample - loss: 0.002\n",
      "Epoch 57/100\n",
      "650/650 [==============================] - 1s 1ms/sample - loss: 0.002\n",
      "Epoch 58/100\n",
      "650/650 [==============================] - 1s 957us/sample - loss: 0.002\n",
      "Epoch 59/100\n",
      "650/650 [==============================] - 1s 975us/sample - loss: 0.002\n",
      "Epoch 60/100\n",
      "650/650 [==============================] - 1s 927us/sample - loss: 0.001\n",
      "Epoch 61/100\n",
      "650/650 [==============================] - 1s 956us/sample - loss: 0.001\n",
      "Epoch 62/100\n",
      "650/650 [==============================] - 1s 992us/sample - loss: 0.001\n",
      "Epoch 63/100\n",
      "650/650 [==============================] - 1s 923us/sample - loss: 0.001\n",
      "Epoch 64/100\n",
      "650/650 [==============================] - 1s 892us/sample - loss: 0.001\n",
      "Epoch 65/100\n",
      "650/650 [==============================] - 1s 926us/sample - loss: 0.001\n",
      "Epoch 66/100\n",
      "650/650 [==============================] - 1s 962us/sample - loss: 0.001\n",
      "Epoch 67/100\n",
      "650/650 [==============================] - 1s 973us/sample - loss: 0.001\n",
      "Epoch 68/100\n",
      "650/650 [==============================] - 1s 929us/sample - loss: 0.001\n",
      "Epoch 69/100\n",
      "650/650 [==============================] - 1s 919us/sample - loss: 0.001\n",
      "Epoch 70/100\n",
      "650/650 [==============================] - 1s 905us/sample - loss: 0.001\n",
      "Epoch 71/100\n",
      "650/650 [==============================] - 1s 913us/sample - loss: 0.001\n",
      "Epoch 72/100\n",
      "650/650 [==============================] - 1s 937us/sample - loss: 0.001\n",
      "Epoch 73/100\n",
      "650/650 [==============================] - 1s 936us/sample - loss: 0.001\n",
      "Epoch 74/100\n",
      "650/650 [==============================] - 1s 906us/sample - loss: 0.001\n",
      "Epoch 75/100\n",
      "650/650 [==============================] - 1s 934us/sample - loss: 0.001\n",
      "Epoch 76/100\n",
      "650/650 [==============================] - 1s 924us/sample - loss: 0.001\n",
      "Epoch 77/100\n",
      "650/650 [==============================] - 1s 941us/sample - loss: 0.001\n",
      "Epoch 78/100\n",
      "650/650 [==============================] - 1s 957us/sample - loss: 0.001\n",
      "Epoch 79/100\n",
      "650/650 [==============================] - 1s 917us/sample - loss: 0.001\n",
      "Epoch 80/100\n",
      "650/650 [==============================] - 1s 973us/sample - loss: 0.001\n",
      "Epoch 81/100\n",
      "650/650 [==============================] - 1s 948us/sample - loss: 0.001\n",
      "Epoch 82/100\n",
      "650/650 [==============================] - 1s 918us/sample - loss: 0.001\n",
      "Epoch 83/100\n",
      "650/650 [==============================] - 1s 954us/sample - loss: 0.001\n",
      "Epoch 84/100\n",
      "650/650 [==============================] - 1s 955us/sample - loss: 0.001\n",
      "Epoch 85/100\n",
      "650/650 [==============================] - 1s 942us/sample - loss: 0.001\n",
      "Epoch 86/100\n",
      "650/650 [==============================] - 1s 943us/sample - loss: 0.001\n",
      "Epoch 87/100\n",
      "650/650 [==============================] - 1s 931us/sample - loss: 0.001\n",
      "Epoch 88/100\n",
      "650/650 [==============================] - 1s 914us/sample - loss: 0.001\n",
      "Epoch 89/100\n",
      "650/650 [==============================] - 1s 961us/sample - loss: 0.001\n",
      "Epoch 90/100\n",
      "650/650 [==============================] - 1s 938us/sample - loss: 0.001\n",
      "Epoch 91/100\n",
      "650/650 [==============================] - 1s 944us/sample - loss: 0.001\n",
      "Epoch 92/100\n",
      "650/650 [==============================] - 1s 939us/sample - loss: 0.001\n",
      "Epoch 93/100\n",
      "650/650 [==============================] - 1s 956us/sample - loss: 0.001\n",
      "Epoch 94/100\n",
      "650/650 [==============================] - 1s 961us/sample - loss: 0.002\n",
      "Epoch 95/100\n",
      "650/650 [==============================] - 1s 980us/sample - loss: 0.003\n",
      "Epoch 96/100\n",
      "650/650 [==============================] - 1s 913us/sample - loss: 0.004\n",
      "Epoch 97/100\n",
      "650/650 [==============================] - 1s 1ms/sample - loss: 0.005\n",
      "Epoch 98/100\n",
      "650/650 [==============================] - 1s 933us/sample - loss: 0.008\n",
      "Epoch 99/100\n",
      "650/650 [==============================] - 1s 942us/sample - loss: 0.008\n",
      "Epoch 100/100\n",
      "650/650 [==============================] - 1s 994us/sample - loss: 0.011\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "model = get_model()\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_d, y_d,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd9db16-1b9e-434c-a46e-37c468e0132e",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1639208835309
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of death in last 7 days: [[752528.1 745079.1 749663.4 754008.1 753389.6 748977.4 750531. ]]\n",
      "The daily new death is: [-26072.875  -7449.      4584.25    4344.75    -618.5    -4412.25\n",
      "   1553.625]\n"
     ]
    }
   ],
   "source": [
    "last_21 = death_train[0][-21::].reshape(1,21,1)\n",
    "pred = model.predict(last_21)\n",
    "pred = (pred * death_std) + death_mean\n",
    "print(\"prediction of death in last 7 days:\",pred)\n",
    "\n",
    "tmp = [(death_train[0][-1] * death_std) + death_mean]\n",
    "tmp.extend(list(pred[0]))\n",
    "print(\"The daily new death is:\",np.diff(tmp))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
